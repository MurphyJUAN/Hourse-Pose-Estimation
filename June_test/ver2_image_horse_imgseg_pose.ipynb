{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ver2_image_horse_imgseg_pose",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_iHs_wm2Mhh"
      },
      "source": [
        "### About Mask R-CNN\n",
        "The Mask R-CNN model addresses one of the most difficult computer vision challenges: image segmentation. Image segmentation is the task of detecting and distinguishing multiple objects within a single image. In particular, Mask R-CNN performs \"instance segmentation,\" which means that different instances of the same type of object in the input image, for example, car, should be assigned distinct labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DL_0tSC67biu"
      },
      "source": [
        "# Instructions\n",
        "<h3><a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a>  &nbsp;&nbsp;Use a free Cloud TPU</h3>\n",
        " \n",
        "   1. On the main menu, click Runtime and select **Change runtime type**. Set \"TPU\" as the hardware accelerator.\n",
        "   2. Click Runtime again and select **Runtime > Run All**. You can also run the cells manually with Shift-ENTER."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODxpKwkNFrBk"
      },
      "source": [
        "## Download the source code\n",
        "Download the source code of the Mask R-CNN model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KfAmRU3xK65",
        "outputId": "ea79a9c6-4d6d-4bc8-e785-701419cda0eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!git clone https://github.com/rwightman/posenet-python.git\n",
        "!git clone https://github.com/tensorflow/tpu/\n",
        "!git clone https://github.com/MurphyJUAN/Hourse-Pose-Estimation.git\n",
        "# %cd /content/posenet-python\n",
        "\n",
        "!pip install tensorflow-gpu \n",
        "!pip install scipy \n",
        "!pip install pyyaml \n",
        "!pip install opencv-python==3.4.5.20\n",
        "%tensorflow_version 1.x\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'posenet-python'...\n",
            "remote: Enumerating objects: 119, done.\u001b[K\n",
            "remote: Total 119 (delta 0), reused 0 (delta 0), pack-reused 119\u001b[K\n",
            "Receiving objects: 100% (119/119), 36.55 KiB | 1.66 MiB/s, done.\n",
            "Resolving deltas: 100% (68/68), done.\n",
            "Cloning into 'tpu'...\n",
            "remote: Enumerating objects: 9576, done.\u001b[K\n",
            "remote: Total 9576 (delta 0), reused 0 (delta 0), pack-reused 9576\u001b[K\n",
            "Receiving objects: 100% (9576/9576), 24.18 MiB | 25.29 MiB/s, done.\n",
            "Resolving deltas: 100% (6862/6862), done.\n",
            "Cloning into 'Hourse-Pose-Estimation'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 353 (delta 3), reused 10 (delta 1), pack-reused 341\u001b[K\n",
            "Receiving objects: 100% (353/353), 73.45 MiB | 39.28 MiB/s, done.\n",
            "Resolving deltas: 100% (147/147), done.\n",
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/99/ac32fd13d56e40d4c3e6150030132519997c0bb1f06f448d970e81b177e5/tensorflow_gpu-2.3.1-cp36-cp36m-manylinux2010_x86_64.whl (320.4MB)\n",
            "\u001b[K     |████████████████████████████████| 320.4MB 22kB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.35.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.32.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.10.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.18.5)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.12.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.3.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow-gpu) (50.3.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.7.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.17.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (3.2.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (2.0.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.2.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.1.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.3.1\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.18.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (3.13)\n",
            "Collecting opencv-python==3.4.5.20\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/e1/d3eed618272f4b746339af1a84b2511e79c1708d88a9195cf25d743fa614/opencv_python-3.4.5.20-cp36-cp36m-manylinux1_x86_64.whl (25.4MB)\n",
            "\u001b[K     |████████████████████████████████| 25.4MB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python==3.4.5.20) (1.18.5)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: opencv-python\n",
            "  Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "Successfully installed opencv-python-3.4.5.20\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZnTbL8CbGsO"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPbB7s8hPHfO"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EtGbyNc8VgS"
      },
      "source": [
        "from IPython import display\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "sys.path.insert(0, 'tpu/models/official')\n",
        "sys.path.insert(0, 'tpu/models/official/mask_rcnn')\n",
        "import coco_metric\n",
        "from mask_rcnn.object_detection import visualization_utils\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkTSG22ePKkz"
      },
      "source": [
        "## Load the COCO index mapping\n",
        "This Colab uses a pretrained checkpoint of the Mask R-CNN model that is trained using the COCO dataset. Here is the mapping between the indices that the model predicts and the categories in text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q5r1zob93OF"
      },
      "source": [
        "ID_MAPPING = {\n",
        "    1: 'person',\n",
        "    2: 'bicycle',\n",
        "    3: 'car',\n",
        "    4: 'motorcycle',\n",
        "    5: 'airplane',\n",
        "    6: 'bus',\n",
        "    7: 'train',\n",
        "    8: 'truck',\n",
        "    9: 'boat',\n",
        "    10: 'traffic light',\n",
        "    11: 'fire hydrant',\n",
        "    13: 'stop sign',\n",
        "    14: 'parking meter',\n",
        "    15: 'bench',\n",
        "    16: 'bird',\n",
        "    17: 'cat',\n",
        "    18: 'dog',\n",
        "    19: 'horse',\n",
        "    20: 'sheep',\n",
        "    21: 'cow',\n",
        "    22: 'elephant',\n",
        "    23: 'bear',\n",
        "    24: 'zebra',\n",
        "    25: 'giraffe',\n",
        "    27: 'backpack',\n",
        "    28: 'umbrella',\n",
        "    31: 'handbag',\n",
        "    32: 'tie',\n",
        "    33: 'suitcase',\n",
        "    34: 'frisbee',\n",
        "    35: 'skis',\n",
        "    36: 'snowboard',\n",
        "    37: 'sports ball',\n",
        "    38: 'kite',\n",
        "    39: 'baseball bat',\n",
        "    40: 'baseball glove',\n",
        "    41: 'skateboard',\n",
        "    42: 'surfboard',\n",
        "    43: 'tennis racket',\n",
        "    44: 'bottle',\n",
        "    46: 'wine glass',\n",
        "    47: 'cup',\n",
        "    48: 'fork',\n",
        "    49: 'knife',\n",
        "    50: 'spoon',\n",
        "    51: 'bowl',\n",
        "    52: 'banana',\n",
        "    53: 'apple',\n",
        "    54: 'sandwich',\n",
        "    55: 'orange',\n",
        "    56: 'broccoli',\n",
        "    57: 'carrot',\n",
        "    58: 'hot dog',\n",
        "    59: 'pizza',\n",
        "    60: 'donut',\n",
        "    61: 'cake',\n",
        "    62: 'chair',\n",
        "    63: 'couch',\n",
        "    64: 'potted plant',\n",
        "    65: 'bed',\n",
        "    67: 'dining table',\n",
        "    70: 'toilet',\n",
        "    72: 'tv',\n",
        "    73: 'laptop',\n",
        "    74: 'mouse',\n",
        "    75: 'remote',\n",
        "    76: 'keyboard',\n",
        "    77: 'cell phone',\n",
        "    78: 'microwave',\n",
        "    79: 'oven',\n",
        "    80: 'toaster',\n",
        "    81: 'sink',\n",
        "    82: 'refrigerator',\n",
        "    84: 'book',\n",
        "    85: 'clock',\n",
        "    86: 'vase',\n",
        "    87: 'scissors',\n",
        "    88: 'teddy bear',\n",
        "    89: 'hair drier',\n",
        "    90: 'toothbrush',\n",
        "}\n",
        "category_index = {k: {'id': k, 'name': ID_MAPPING[k]} for k in ID_MAPPING}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwrFI4C9Vvam"
      },
      "source": [
        "## Create a Tensorflow session\n",
        "Now let us create a Tensorflow session to run the inference. You can either connect to a TPU or a normal CPU backend."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0G-tk6wakcr",
        "outputId": "69d1a913-b6fb-4dab-bcaa-f36372890584",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "use_tpu = True #@param {type:\"boolean\"}\n",
        "if use_tpu:\n",
        "  import os\n",
        "  import pprint\n",
        " \n",
        "  assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "  TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  print('TPU address is', TPU_ADDRESS)\n",
        " \n",
        "  session = tf.Session(TPU_ADDRESS, graph=tf.Graph())\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "else:\n",
        "  session = tf.Session(graph=tf.Graph())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.7.98.122:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 13089126461110143688),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 14150893121147282938),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 3697912295167038476),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 7274147243270079244),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 12265263366930111155),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 12415887145084129887),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 7743345860936133567),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 8217273862579964422),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 9468453215557572456),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 15777236459752343889),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 14648492147930207980)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HngQNsyjXmvF"
      },
      "source": [
        "## Load an image\n",
        "Now, you can load an image. Use either the sample image included here, or update the field with an image of your choice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZuj0Lpu0YV3"
      },
      "source": [
        "!mkdir share_folder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtXyXw6EaKRj"
      },
      "source": [
        "# Load the pretrained model\n",
        "Loading the COCO pretrained saved model from the public GCS bucket. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lCL-ZcwaJbA",
        "outputId": "15be6fdb-ac6c-4cf2-979a-d3ff80e44650",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "saved_model_dir = 'gs://cloud-tpu-checkpoints/mask-rcnn/1555659850' #@param {type:\"string\"}\n",
        "_ = tf.saved_model.loader.load(session, ['serve'], saved_model_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-6-9cb25c67e8d4>:2: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
            "INFO:tensorflow:Restoring parameters from gs://cloud-tpu-checkpoints/mask-rcnn/1555659850/variables/variables\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3X27A_hD1XQ2"
      },
      "source": [
        "## Function define"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWay6heR1Eq_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "# %matplotlib inline\n",
        "def maskRCNN_humantojpg(image_path):\n",
        "  \n",
        "  with open(image_path, 'rb') as f:\n",
        "    np_image_string = np.array([f.read()])\n",
        "\n",
        "  image = Image.open(image_path)\n",
        "  # plt.imshow(image)\n",
        "  width, height = image.size\n",
        "  # np_image = np.array(image.getdata()).reshape(height, width, 3).astype(np.uint8)\n",
        "\n",
        "  num_detections, detection_boxes, detection_classes, detection_scores, detection_masks, image_info = session.run(\n",
        "    ['NumDetections:0', 'DetectionBoxes:0', 'DetectionClasses:0', 'DetectionScores:0', 'DetectionMasks:0', 'ImageInfo:0'],\n",
        "    feed_dict={'Placeholder:0': np_image_string})\n",
        " \n",
        "  num_detections = np.squeeze(num_detections.astype(np.int32), axis=(0,))\n",
        "  detection_boxes = np.squeeze(detection_boxes * image_info[0, 2], axis=(0,))[0:num_detections]\n",
        "  detection_scores = np.squeeze(detection_scores, axis=(0,))[0:num_detections]\n",
        "  detection_classes = np.squeeze(detection_classes.astype(np.int32), axis=(0,))[0:num_detections]\n",
        "  instance_masks = np.squeeze(detection_masks, axis=(0,))[0:num_detections]\n",
        "  ymin, xmin, ymax, xmax = np.split(detection_boxes, 4, axis=-1)\n",
        "  processed_boxes = np.concatenate([xmin, ymin, xmax - xmin, ymax - ymin], axis=-1)\n",
        "  segmentations = coco_metric.generate_segmentation_from_masks(instance_masks, processed_boxes, height, width) # 所有在coco dataset內的物件\n",
        "\n",
        "  cond1 = np.where(detection_classes == 1)[0].tolist()\n",
        "  cond2 = np.where(detection_scores >= 0.5)[0].tolist()\n",
        "  per_index = [i for i in cond1 if i in cond2]\n",
        "  # print(per_index)\n",
        "  detection_scores[per_index]\n",
        "  # detection_boxes[per_index] is person \n",
        "  print(len(per_index))\n",
        "  new_image = np.array(image.getdata()).reshape(height, width, 3).astype(np.uint8)\n",
        "  # plt.imshow(segmentations[0])\n",
        "  # plt.show()\n",
        "  for i in range(len(per_index)):\n",
        "    index = detection_boxes[per_index][i].astype(np.uint16)\n",
        "    # print(len(per_index))\n",
        "  # print(np.shape(segmentations[0]))\n",
        "    mas = segmentations[per_index[i]][index[0]:index[2], index[1]:index[3]] \n",
        "    pic = new_image[index[0]:index[2], index[1]:index[3]]\n",
        "    # plt.imshow(mas)\n",
        "    # plt.show()\n",
        "    seg_pic=cv2.add(pic, np.zeros(np.shape(pic), dtype=np.uint8), mask=mas)\n",
        "\n",
        "    image_name = image_path.split(\"/\")[-1][:-4]\n",
        "    save_path = '/content/share_folder/'\n",
        "    save_name = save_path+image_name+'_'+str(i)+'.jpg'\n",
        "    print(save_name)\n",
        "    save_tick = cv2.imwrite(save_name, seg_pic[...,::-1])\n",
        "\n",
        "    if save_tick:\n",
        "      print('image save in:', save_name)  "
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kskAIsf8DpVn"
      },
      "source": [
        "!rm -f /content/output_image/*\n",
        "!rm -f /content/share_folder/*"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK5axJ3b2Ehw",
        "outputId": "d9bb41c6-b973-4211-a6a3-ceb9ee95d85d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "%cd /content/\n",
        "maskRCNN_humantojpg('/content/Hourse-Pose-Estimation/data/images/駝背(30)_2.JPG')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "[1]\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/content/share_folder/駝背(30)_2_0.jpg\n",
            "image save in: /content/share_folder/駝背(30)_2_0.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVXAmh999o1u",
        "outputId": "9c2c6344-6f12-49bd-b868-6c09bbc1eb74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "%cd /content/posenet-python\n",
        "!python3 image_demo.py --model 101 --image_dir /content/share_folder --output_dir /content/output_image"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/posenet-python\n",
            "WARNING:tensorflow:From image_demo.py:21: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-10-08 17:24:48.167779: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-10-08 17:24:48.176409: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-10-08 17:24:48.176461: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (4b778d609097): /proc/driver/nvidia/version does not exist\n",
            "2020-10-08 17:24:48.183099: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-10-08 17:24:48.183418: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1518a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-08 17:24:48.183468: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "WARNING:tensorflow:From /content/posenet-python/posenet/model.py:45: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/posenet-python/posenet/model.py:46: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
            "\n",
            "\n",
            "Results for image: /content/share_folder/駝背(30)_2_0.jpg\n",
            "Average FPS: 0.7862501305166849\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9GYxWiuFGZL"
      },
      "source": [
        "## ALL image test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E-bzIkLFMIL",
        "outputId": "edc573f3-f8c7-4b72-ae70-8d723ec93113",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os \n",
        "img_list = os.listdir('/content/Hourse-Pose-Estimation/data/images')\n",
        "img_list[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stand_normal.JPG', '駝背(30)_2.JPG', '駝背(30).JPG']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJIX-ogvFoZL",
        "outputId": "27b34741-c70b-451f-900f-65097cc1b4da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('ass%s'%'baa')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "assbaa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3B3zSUsFYob",
        "outputId": "c2a90cd3-c4ef-4adf-a0b9-24d27905d438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        }
      },
      "source": [
        "%cd /content/\n",
        "for i in img_list:\n",
        "  maskRCNN_humantojpg('/content/Hourse-Pose-Estimation/data/images/%s'%i)\n",
        "  # print('/content/Hourse-Pose-Estimation/data/images/%s'%i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "1\n",
            "/content/share_folder/stand_normal_0.jpg\n",
            "image save in: /content/share_folder/stand_normal_0.jpg\n",
            "1\n",
            "/content/share_folder/駝背(30)_2_0.jpg\n",
            "image save in: /content/share_folder/駝背(30)_2_0.jpg\n",
            "2\n",
            "/content/share_folder/駝背(30)_0.jpg\n",
            "image save in: /content/share_folder/駝背(30)_0.jpg\n",
            "/content/share_folder/駝背(30)_1.jpg\n",
            "image save in: /content/share_folder/駝背(30)_1.jpg\n",
            "1\n",
            "/content/share_folder/馬術錯誤6_0.jpg\n",
            "image save in: /content/share_folder/馬術錯誤6_0.jpg\n",
            "1\n",
            "/content/share_folder/立正(90)_0.jpg\n",
            "image save in: /content/share_folder/立正(90)_0.jpg\n",
            "1\n",
            "/content/share_folder/駝背(180)_2_0.jpg\n",
            "image save in: /content/share_folder/駝背(180)_2_0.jpg\n",
            "1\n",
            "/content/share_folder/馬術錯誤2_0.jpg\n",
            "image save in: /content/share_folder/馬術錯誤2_0.jpg\n",
            "1\n",
            "/content/share_folder/馬術錯誤4_0.jpg\n",
            "image save in: /content/share_folder/馬術錯誤4_0.jpg\n",
            "1\n",
            "/content/share_folder/立正(150)_0.jpg\n",
            "image save in: /content/share_folder/立正(150)_0.jpg\n",
            "1\n",
            "/content/share_folder/駝背(60)_2_0.jpg\n",
            "image save in: /content/share_folder/駝背(60)_2_0.jpg\n",
            "1\n",
            "/content/share_folder/馬術錯誤_2(3)_0.jpg\n",
            "image save in: /content/share_folder/馬術錯誤_2(3)_0.jpg\n",
            "2\n",
            "/content/share_folder/立正(120)_3_0.jpg\n",
            "image save in: /content/share_folder/立正(120)_3_0.jpg\n",
            "/content/share_folder/立正(120)_3_1.jpg\n",
            "image save in: /content/share_folder/立正(120)_3_1.jpg\n",
            "1\n",
            "/content/share_folder/馬術錯誤_2(4)_0.jpg\n",
            "image save in: /content/share_folder/馬術錯誤_2(4)_0.jpg\n",
            "1\n",
            "/content/share_folder/駝背(60)_0.jpg\n",
            "image save in: /content/share_folder/駝背(60)_0.jpg\n",
            "1\n",
            "/content/share_folder/立正(0)_4_0.jpg\n",
            "image save in: /content/share_folder/立正(0)_4_0.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8-xpsYOFJPq"
      },
      "source": [
        "%cd /content/posenet-python\n",
        "!python3 image_demo.py --model 101 --image_dir /content/share_folder --output_dir /content/output_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRbTeBDsRM77"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}